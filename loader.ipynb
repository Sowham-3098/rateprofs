{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 2: Import libraries\n",
    "import json\n",
    "import os\n",
    "import pinecone\n",
    "import requests\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"reviews.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Initialize Pinecone\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# pc.create_index(\n",
    "#   name=\"rag1\", \n",
    "#   dimension=1536,\n",
    "#   metric=\"cosine\",\n",
    "#   spec=ServerlessSpec(\n",
    "#     cloud=\"aws\",\n",
    "#     region=\"us-east-1\"\n",
    "#   )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(\"rag1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai.GenerativeModel(\n",
      "    model_name='models/gemini-1.5-flash',\n",
      "    generation_config={'temperature': 1, 'top_p': 0.95, 'top_k': 64, 'max_output_tokens': 8192, 'response_mime_type': 'text/plain'},\n",
      "    safety_settings={},\n",
      "    tools=None,\n",
      "    system_instruction=None,\n",
      "    cached_content=None\n",
      ")\n",
      "[text: \"This is a great start! It effectively describes Dr. Smith\\'s teaching style and provides positive feedback. You could enhance it further by adding more specific details. Here are some ideas:\\n\\n**Adding specific details:**\\n\\n* **Examples of his teaching methods:** Does he use real-world examples, interactive activities, or visual aids to make concepts clear? \\n* **Specific instances of clarity:**  Can you recall a particular lecture where Dr. Smith explained a challenging topic in a way that made it understandable? \\n* **Impact on your learning:**  How has Dr. Smith\\'s teaching influenced your understanding of the subject? \\n\\n**Adding a personal touch:**\\n\\n* **Why you appreciate his teaching style:**  What is it about Dr. Smith\\'s approach that makes his lectures engaging and informative for you? \\n* **Anecdotes:**  Do you have any specific memories or experiences from Dr. Smith\\'s class that illustrate his teaching excellence?\\n\\n**Here are some examples of how to expand on your statement:**\\n\\n* **\\\"Dr. Smith is an excellent professor who explains complex concepts with ease. His lectures are engaging and informative, often incorporating real-world examples and interactive discussions that make even the most challenging material come to life. His ability to simplify complex ideas has significantly enhanced my understanding of the subject.\\\"**\\n* **\\\"I vividly recall a lecture where Dr. Smith broke down the concept of quantum mechanics in a way that was both clear and captivating. His use of analogies and visual aids made it easy to grasp, even for those who had limited prior knowledge. Dr. Smith\\'s enthusiasm and passion for the subject are contagious, making his lectures a highlight of my academic week.\\\"**\\n\\nRemember, the more specific and detailed your feedback is, the more impactful it will be for Dr. Smith and others who read it. \\n\"\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GenerateContentResponse' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedding_text)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Assume the embedding is returned as part of the response\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Make sure to verify the structure of the response\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Use .get() for safety\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Append processed data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m processed_data\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     23\u001b[0m     {\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     }\n\u001b[0;32m     32\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'GenerateContentResponse' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "\n",
    "# Assuming 'model' is properly initialized and refers to your Gemini model instance\n",
    "print(model)\n",
    "\n",
    "for review in data:\n",
    "  \n",
    "        # Generate the embedding using the Gemini model\n",
    "        response = model.generate_content(\n",
    "           review[\"review\"]\n",
    "        )\n",
    "        embedding_text= response.candidates[0].content.parts['text']\n",
    "\n",
    "        print(embedding_text)\n",
    "        # Assume the embedding is returned as part of the response\n",
    "        # Make sure to verify the structure of the response\n",
    "        embedding = response['embedding']  # Use .get() for safety\n",
    "\n",
    "        \n",
    "\n",
    "        # Append processed data\n",
    "        processed_data.append(\n",
    "            {\n",
    "                \"values\": embedding,\n",
    "                \"id\": review[\"professor\"],  # Use a unique identifier\n",
    "                \"metadata\": {\n",
    "                    \"review\": review[\"review\"],\n",
    "                    \"subject\": review[\"subject\"],\n",
    "                    \"stars\": review[\"stars\"],\n",
    "                }\n",
    "            }\n",
    "        )\n",
    " \n",
    "\n",
    "# Now processed_data contains the embeddings and associated metadata\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
